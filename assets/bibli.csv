"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"EWQEH3CC","journalArticle","2018","Frid-Adar, Maayan; Diamant, Idit; Klang, Eyal; Amitai, Michal; Goldberger, Jacob; Greenspan, Hayit","GAN-based Synthetic Medical Image Augmentation for increased CNN Performance in Liver Lesion Classification","Neurocomputing","","09252312","10.1016/j.neucom.2018.09.013","http://arxiv.org/abs/1803.01229","Deep learning methods, and in particular convolutional neural networks (CNNs), have led to an enormous breakthrough in a wide range of computer vision tasks, primarily by using large-scale annotated datasets. However, obtaining such datasets in the medical domain remains a challenge. In this paper, we present methods for generating synthetic medical images using recently presented deep learning Generative Adversarial Networks (GANs). Furthermore, we show that generated medical images can be used for synthetic data augmentation, and improve the performance of CNN for medical image classiﬁcation. Our novel method is demonstrated on a limited dataset of computed tomography (CT) images of 182 liver lesions (53 cysts, 64 metastases and 65 hemangiomas). We ﬁrst exploit GAN architectures for synthesizing high quality liver lesion ROIs. Then we present a novel scheme for liver lesion classiﬁcation using CNN. Finally, we train the CNN using classic data augmentation and our synthetic data augmentation and compare performance. In addition, we explore the quality of our synthesized examples using visualization and expert assessment. The classiﬁcation performance using only classic data augmentation yielded 78.6% sensitivity and 88.4% speciﬁcity. By adding the synthetic data augmentation the results increased to 85.7% sensitivity and 92.4% speciﬁcity. We believe that this approach to synthetic data augmentation can generalize to other medical classiﬁcation applications and thus support radiologists’ efforts to improve diagnosis.","2018-12","2019-02-04 16:51:18","2019-02-04 16:51:18","2019-02-04 16:51:18","321-331","","","321","","","","","","","","","","en","","","","","arXiv.org","","arXiv: 1803.01229","","/Users/trislaz/Zotero/storage/GBKI4NQP/Frid-Adar et al. - 2018 - GAN-based Synthetic Medical Image Augmentation for.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TANP52S7","journalArticle","2013","Saavedra, Serguei; Stouffer, Daniel B.","“Disentangling nestedness” disentangled","Nature","","1476-4687","10.1038/nature12380","https://www.nature.com/articles/nature12380","Arising from A. James, J. W. Pitchford & M. J. Plank Nature 487, 227–230 (2012)10.1038/nature11214Analytical research indicates that the ‘nestedness’ of mutualistic networks facilitates the coexistence of species by minimizing the costs of competition relative to the benefits of facilitation1. In contrast, James et al.2 recently argued that a more parsimonious explanation exists: the persistence of a community and its constituent species depends more on their having many interactions (high connectance and high degree, respectively) than for these interactions to be organized in any particular manner. Here we demonstrate that these conclusions are an unintended consequence of the fact that the methodology of ref. 2 directly changed the number of interactions of each species—and hence their expected persistence. When these changes are taken into account, we find a significant, positive relationship between nestedness and network persistence that reconfirms the importance of nestedness in mutualistic communities1,3. There is a Reply to this Brief Communication Arising by James, A., Pitchford, J. W. & Plank, M. J. Nature 500, http://dx.doi.org/10.1038/nature12381 (2013).","2013-08","2019-01-07 16:58:50","2019-01-07 16:58:50","2019-01-07 16:58:50","E1-E2","","7463","500","","","","","","","","","","en","2013 Nature Publishing Group","","","","www.nature.com","","","","/Users/trislaz/Zotero/storage/CGTRVP78/Saavedra et Stouffer - 2013 - “Disentangling nestedness” disentangled.pdf; /Users/trislaz/Zotero/storage/EGJRN7AW/nature12380.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
FSZH63UQ","journalArticle","2023","Wang, Xiyue; Cai, De; Yang, Sen; Cui, Yiming; Zhu, Junyou; Wang, Kanran; Zhao, Junhan","SAC-Net: Enhancing Spatiotemporal Aggregation in Cervical Histological Image Classification via Label-Efficient Weakly Supervised Learning","IEEE Transactions on Circuits and Systems for Video Technology","","1558-2205","10.1109/TCSVT.2023.3294938","","Cervical cancer is the fourth most common cancer in women and its subtyping requires examining histopathological slides or digital images, such as whole slide images (WSIs). However, manually inspecting WSIs with gigapixel sizes can be laborious and prone to errors for pathologists. To address this issue, computer-aided approaches based on weakly-supervised learning techniques have been proposed. These methods can predict disease types directly from WSIs and highlight diagnosis-relevant regions, which can help pathologists achieve faster and more accurate diagnoses. WSIs are divided into overlapping patches using a sliding window approach, and these patches are subsequently screened in a sequential zig-zag pattern to identify spatiotemporal dependencies. These dependencies are further analyzed to generate predictions at the WSI level. Therefore, effective patch feature learning and spatiotemporal aggregation are two key issues in the weakly-supervised WSI classification (WSWC) task. In this paper, we present a label-efficient WSWC method called spatiotemporal aggregation for cervical WSIs (SAC-Net), which jointly performs online feature extraction and feature aggregation to infer the WSI-level prediction in an end-to-end manner. The online feature extractor helps to learn cervical-cancer-specific features and obtain more accurate patch representations. The feature aggregator uses an online instance clustering method to learn proper weight parameters for each cluster, which generates the WSI embedding with enhanced spatiotemporal aggregation. SAC-Net is developed and evaluated on a public cervical WSI dataset (TissueNet) containing 1015 WSIs, which are also externally tested on three independent cervical WSI datasets. Our results demonstrate that SAC-Net achieves state-of-the-art classification performance and is robust. SAC-Net has the potential to be a useful tool for clinical cervical cancer detection.","2023","2023-07-18 08:04:43","2023-07-18 08:04:43","","1-1","","","","","","SAC-Net","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Circuits and Systems for Video Technology","","/Users/trislaz/Zotero/storage/BU3M7QMK/10182306.html","","","Annotations; Feature extraction; Cervical histopathology; label-efficient weakly-supervised learning; Lesions; Manuals; online feature clustering; spatiotemporal aggregation; Spatiotemporal phenomena; Supervised learning; Task analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
